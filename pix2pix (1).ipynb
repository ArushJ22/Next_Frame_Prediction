{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Tx9_SUIPrp",
        "outputId": "6ddf07c4-9537-45e2-ae07-e4cd996c2c53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape (X): torch.Size([16, 1, 64, 64])\n",
            "Target shape (Y): torch.Size([16, 1, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Dataset Path\n",
        "data_path = 'mnist_test_seq.npy'\n",
        "\n",
        "# Load Data as Numpy Array\n",
        "MovingMNIST = np.load(data_path).transpose(1, 0, 2, 3)  # Shape: (10000, 20, 64, 64)\n",
        "\n",
        "# Shuffle Data\n",
        "np.random.shuffle(MovingMNIST)\n",
        "\n",
        "# Split into Train, Validation, and Test\n",
        "train_data = MovingMNIST[:8000]   # 8000 samples for training\n",
        "val_data = MovingMNIST[8000:9000] # 1000 samples for validation\n",
        "test_data = MovingMNIST[9000:]    # 1000 samples for testing\n",
        "\n",
        "# Define custom Dataset that returns (frame_t, frame_t+1) pairs\n",
        "class FramePairDataset(Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.pairs = []\n",
        "        for seq in sequences:\n",
        "            for i in range(19):  # Create 19 pairs per sequence\n",
        "                input_frame = seq[i]\n",
        "                target_frame = seq[i + 1]\n",
        "                self.pairs.append((input_frame, target_frame))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.pairs[idx]\n",
        "        x = torch.tensor(x, dtype=torch.float32).unsqueeze(0) / 255.0  # Normalize and add channel dim\n",
        "        y = torch.tensor(y, dtype=torch.float32).unsqueeze(0) / 255.0\n",
        "        return x, y  # Shapes: (1, 64, 64)\n",
        "\n",
        "# Batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(FramePairDataset(train_data), batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(FramePairDataset(val_data), batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(FramePairDataset(test_data), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check shapes\n",
        "sample_X, sample_Y = next(iter(train_loader))\n",
        "print(f\"Input shape (X): {sample_X.shape}\")  # Expected: (batch_size, 1, 64, 64)\n",
        "print(f\"Target shape (Y): {sample_Y.shape}\")  # Expected: (batch_size, 1, 64, 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHGlYLioIPrt",
        "outputId": "ed26fb41-3532-4175-c87e-561587cbcca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator output shape: torch.Size([8, 1, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a U-Net block\n",
        "class UNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_dropout=False):\n",
        "        super(UNetBlock, self).__init__()\n",
        "        if down:\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5) if use_dropout else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.use_dropout:\n",
        "            x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# Define U-Net Generator\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=1, features=[64, 128, 256, 512]):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "        # Encoder (Downsampling)\n",
        "        self.enc1 = UNetBlock(in_channels, features[0], down=True, use_dropout=False)   # 64x64 -> 32x32\n",
        "        self.enc2 = UNetBlock(features[0], features[1], down=True, use_dropout=False)   # 32x32 -> 16x16\n",
        "        self.enc3 = UNetBlock(features[1], features[2], down=True, use_dropout=False)   # 16x16 -> 8x8\n",
        "        self.enc4 = UNetBlock(features[2], features[3], down=True, use_dropout=False)   # 8x8 -> 4x4\n",
        "        self.enc5 = UNetBlock(features[3], features[3], down=True, use_dropout=False)   # 4x4 -> 2x2\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features[3], features[3], kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )  # 2x2 -> 1x1\n",
        "\n",
        "        # Decoder (Upsampling)\n",
        "        self.dec5 = UNetBlock(features[3], features[3], down=False, use_dropout=True)   # 1x1 -> 2x2\n",
        "        self.dec4 = UNetBlock(features[3] * 2, features[3], down=False, use_dropout=False)  # 2x2 -> 4x4\n",
        "        self.dec3 = UNetBlock(features[3] * 2, features[2], down=False, use_dropout=False)  # 4x4 -> 8x8\n",
        "        self.dec2 = UNetBlock(features[2] * 2, features[1], down=False, use_dropout=False)  # 8x8 -> 16x16\n",
        "        self.dec1 = UNetBlock(features[1] * 2, features[0], down=False, use_dropout=False)  # 16x16 -> 32x32\n",
        "\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features[0]* 2, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()  # Outputs in range [-1, 1]\n",
        "        )  # 32x32 -> 64x64\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Downsampling\n",
        "        d1 = self.enc1(x)\n",
        "        d2 = self.enc2(d1)\n",
        "        d3 = self.enc3(d2)\n",
        "        d4 = self.enc4(d3)\n",
        "        d5 = self.enc5(d4)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(d5)\n",
        "\n",
        "        # Upsampling with skip connections (Concatenation)\n",
        "        u5 = self.dec5(b)\n",
        "        u5 = torch.cat([u5, d5], dim=1)\n",
        "\n",
        "        u4 = self.dec4(u5)\n",
        "        u4 = torch.cat([u4, d4], dim=1)\n",
        "\n",
        "        u3 = self.dec3(u4)\n",
        "        u3 = torch.cat([u3, d3], dim=1)\n",
        "\n",
        "        u2 = self.dec2(u3)\n",
        "        u2 = torch.cat([u2, d2], dim=1)\n",
        "\n",
        "        u1 = self.dec1(u2)\n",
        "        u1 = torch.cat([u1, d1], dim=1)\n",
        "\n",
        "        return self.final(u1)\n",
        "\n",
        "# Initialize Generator\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "generator = UNetGenerator(in_channels=1).to(device)\n",
        "\n",
        "\n",
        "# Test generator output shape\n",
        "x = torch.randn((8, 1, 64, 64)).to(device)\n",
        "\n",
        "y_pred = generator(x)\n",
        "print(f\"Generator output shape: {y_pred.shape}\")  # Expected: (8, 1, 64, 64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeVl3f61IPru",
        "outputId": "39b87531-a643-4a62-a78d-655df1737e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discriminator output shape: torch.Size([8, 1, 6, 6])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PatchGANDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels=2, features=[64, 128, 256, 512]):\n",
        "        super(PatchGANDiscriminator, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1, bias=False),  #64×64 → 32×32\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            conv_block(features[0], features[1], stride=2),\n",
        "            conv_block(features[1], features[2], stride=2),\n",
        "            conv_block(features[2], features[3], stride=1),\n",
        "\n",
        "            nn.Conv2d(features[3], 1, kernel_size=4, stride=1, padding=1)  \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) \n",
        "\n",
        "\n",
        "# Initialize Discriminator\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "discriminator = PatchGANDiscriminator().to(device)\n",
        "\n",
        "# Test discriminator output shape\n",
        "x = torch.randn((8, 2, 64, 64)).to(device) \n",
        "y_pred = discriminator(x)\n",
        "print(f\"Discriminator output shape: {y_pred.shape}\")  # Expected: (8, 1, 6, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sCOa9ABjIPrv"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class MovingMNISTDataset(Dataset):\n",
        "    def __init__(self, npy_file):\n",
        "        self.data = np.load(npy_file)  # Shape: (20, 10000, 64, 64)\n",
        "        self.data = self.data.transpose(1, 0, 2, 3)  # New Shape: (10000, 20, 64, 64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.data[idx] / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        input_frame = sequence[0]    # Frame at time t\n",
        "        target_frame = sequence[1]   # Frame at time t+1\n",
        "\n",
        "        # Add channel dimension: (64, 64) -> (1, 64, 64)\n",
        "        input_frame = torch.tensor(input_frame, dtype=torch.float32).unsqueeze(0)\n",
        "        target_frame = torch.tensor(target_frame, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return input_frame, target_frame\n",
        "\n",
        "# Load Dataset\n",
        "dataset = MovingMNISTDataset(\"mnist_test_seq.npy\")\n",
        "\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAaLm2M1IPrv",
        "outputId": "5c5ad596-0a8a-44d6-b210-5e7943b0f5a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]: 100%|██████████| 1250/1250 [00:44<00:00, 27.97it/s, Disc_Loss=0, Gen_Loss=1.36]\n",
            "Epoch [2/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.88it/s, Disc_Loss=0.163, Gen_Loss=10.6]\n",
            "Epoch [3/50]: 100%|██████████| 1250/1250 [00:44<00:00, 27.87it/s, Disc_Loss=0, Gen_Loss=0.933]\n",
            "Epoch [4/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.83it/s, Disc_Loss=0.163, Gen_Loss=9.85]\n",
            "Epoch [5/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.62it/s, Disc_Loss=0, Gen_Loss=1.04] \n",
            "Epoch [6/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.79it/s, Disc_Loss=0.164, Gen_Loss=9.72]\n",
            "Epoch [7/50]: 100%|██████████| 1250/1250 [00:44<00:00, 27.84it/s, Disc_Loss=0, Gen_Loss=0.983]\n",
            "Epoch [8/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.75it/s, Disc_Loss=0.163, Gen_Loss=10.8]\n",
            "Epoch [9/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.76it/s, Disc_Loss=0, Gen_Loss=1.29] \n",
            "Epoch [10/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.74it/s, Disc_Loss=0.167, Gen_Loss=7.02] \n",
            "Epoch [11/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.77it/s, Disc_Loss=0, Gen_Loss=0.83] \n",
            "Epoch [12/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.71it/s, Disc_Loss=0.163, Gen_Loss=12.5]\n",
            "Epoch [13/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.58it/s, Disc_Loss=0, Gen_Loss=1.92]\n",
            "Epoch [14/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.70it/s, Disc_Loss=0.163, Gen_Loss=15]  \n",
            "Epoch [15/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.73it/s, Disc_Loss=0, Gen_Loss=1.81] \n",
            "Epoch [16/50]: 100%|██████████| 1250/1250 [01:07<00:00, 18.64it/s, Disc_Loss=0.163, Gen_Loss=11.4]\n",
            "Epoch [17/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.30it/s, Disc_Loss=0, Gen_Loss=2.04] \n",
            "Epoch [18/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.78it/s, Disc_Loss=0.163, Gen_Loss=12.9]\n",
            "Epoch [19/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.69it/s, Disc_Loss=0, Gen_Loss=1.13] \n",
            "Epoch [20/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.71it/s, Disc_Loss=0.163, Gen_Loss=15.2]\n",
            "Epoch [21/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.69it/s, Disc_Loss=0, Gen_Loss=1.16] \n",
            "Epoch [22/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.70it/s, Disc_Loss=0.163, Gen_Loss=10.9]\n",
            "Epoch [23/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.63it/s, Disc_Loss=0, Gen_Loss=6.3]  \n",
            "Epoch [24/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.67it/s, Disc_Loss=0.163, Gen_Loss=12.7]\n",
            "Epoch [25/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.73it/s, Disc_Loss=0, Gen_Loss=0.954]\n",
            "Epoch [26/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.70it/s, Disc_Loss=0.168, Gen_Loss=6.29]\n",
            "Epoch [27/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.68it/s, Disc_Loss=0, Gen_Loss=0.729]\n",
            "Epoch [28/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.69it/s, Disc_Loss=0.163, Gen_Loss=12.3]\n",
            "Epoch [29/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.74it/s, Disc_Loss=0, Gen_Loss=2.02]\n",
            "Epoch [30/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.70it/s, Disc_Loss=0.163, Gen_Loss=13.4]\n",
            "Epoch [31/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.65it/s, Disc_Loss=0, Gen_Loss=12.4]\n",
            "Epoch [32/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.71it/s, Disc_Loss=0.163, Gen_Loss=16.6]\n",
            "Epoch [33/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.72it/s, Disc_Loss=0, Gen_Loss=10.5]\n",
            "Epoch [34/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.72it/s, Disc_Loss=0.163, Gen_Loss=9.31]\n",
            "Epoch [35/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.69it/s, Disc_Loss=0, Gen_Loss=6.14]\n",
            "Epoch [36/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.72it/s, Disc_Loss=0.163, Gen_Loss=11.7]\n",
            "Epoch [37/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.74it/s, Disc_Loss=0, Gen_Loss=8.06]\n",
            "Epoch [38/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.70it/s, Disc_Loss=0.163, Gen_Loss=10.6]\n",
            "Epoch [39/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.71it/s, Disc_Loss=0, Gen_Loss=3.07] \n",
            "Epoch [40/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.71it/s, Disc_Loss=0.163, Gen_Loss=16.7]\n",
            "Epoch [41/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.71it/s, Disc_Loss=0, Gen_Loss=5.04]\n",
            "Epoch [42/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.72it/s, Disc_Loss=0.163, Gen_Loss=11.3]\n",
            "Epoch [43/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.72it/s, Disc_Loss=0, Gen_Loss=9.87]\n",
            "Epoch [44/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.69it/s, Disc_Loss=0.163, Gen_Loss=13]  \n",
            "Epoch [45/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.67it/s, Disc_Loss=0, Gen_Loss=9.19]\n",
            "Epoch [46/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.68it/s, Disc_Loss=0.163, Gen_Loss=16.4]\n",
            "Epoch [47/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.73it/s, Disc_Loss=0, Gen_Loss=1.25] \n",
            "Epoch [48/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.69it/s, Disc_Loss=0.163, Gen_Loss=15.9]\n",
            "Epoch [49/50]: 100%|██████████| 1250/1250 [00:45<00:00, 27.43it/s, Disc_Loss=0, Gen_Loss=15.5]\n",
            "Epoch [50/50]: 100%|██████████| 1250/1250 [01:06<00:00, 18.70it/s, Disc_Loss=0.163, Gen_Loss=13.5]\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize Generator and Discriminator\n",
        "generator = UNetGenerator(in_channels=1).to(device)\n",
        "discriminator = PatchGANDiscriminator(in_channels=2).to(device)  # 1 input + 1 target = 2 channels\n",
        "\n",
        "# Optimizers\n",
        "lr = 2e-4\n",
        "beta1, beta2 = 0.5, 0.999\n",
        "gen_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "disc_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "# Loss functions\n",
        "bce_loss = nn.BCEWithLogitsLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    lambda_L1 = 10 # Decaying L1 loss weight\n",
        "    loop = tqdm(dataloader, leave=True)\n",
        "\n",
        "    for i, (input_frames, real_next_frame) in enumerate(loop):\n",
        "        input_frames = input_frames.to(device)           # (B, 1, 64, 64)\n",
        "        real_next_frame = real_next_frame.to(device)     # (B, 1, 64, 64)\n",
        "\n",
        "        # ===== Forward Pass =====\n",
        "        fake_next_frame = generator(input_frames)\n",
        "\n",
        "        # Create real and fake pairs for discriminator\n",
        "        real_pair = torch.cat((input_frames, real_next_frame), dim=1)  # (B, 2, 64, 64)\n",
        "        fake_pair = torch.cat((input_frames, fake_next_frame), dim=1)  # (B, 2, 64, 64)\n",
        "\n",
        "        # ===== Train Discriminator =====\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            for _ in range(2): \n",
        "                disc_real = discriminator(real_pair)\n",
        "                disc_fake = discriminator(fake_pair.detach())\n",
        "\n",
        "                loss_real = bce_loss(disc_real, torch.full_like(disc_real, 0.9))\n",
        "                loss_fake = bce_loss(disc_fake, torch.zeros_like(disc_fake))\n",
        "                disc_loss = (loss_real + loss_fake) / 2\n",
        "\n",
        "                disc_optimizer.zero_grad()\n",
        "                disc_loss.backward()\n",
        "                disc_optimizer.step()\n",
        "        else:\n",
        "            disc_loss = torch.tensor(0.0).to(device)\n",
        "\n",
        "        # ===== Train Generator =====\n",
        "        disc_fake = discriminator(fake_pair)\n",
        "        adversarial_loss = bce_loss(disc_fake, torch.ones_like(disc_fake))\n",
        "        l1_loss_value = l1_loss(fake_next_frame, real_next_frame) * lambda_L1\n",
        "        gen_loss = adversarial_loss + l1_loss_value\n",
        "\n",
        "        gen_optimizer.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        # Logging\n",
        "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        loop.set_postfix(Gen_Loss=gen_loss.item(), Disc_Loss=disc_loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X2qhkaR6IPrw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Function to visualize real and generated frames\n",
        "def visualize_samples(epoch, input_frames, real_next_frame, fake_next_frame, save_path=\"generated_samples\"):\n",
        "    os.makedirs(save_path, exist_ok=True)  # Create folder if not exists\n",
        "\n",
        "    fig, axes = plt.subplots(3, 8, figsize=(15, 5))  # 3 rows: input, real, fake\n",
        "\n",
        "    for i in range(8):  # Show first 8 samples\n",
        "        axes[0, i].imshow(input_frames[i, -1].cpu().detach().numpy(), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        axes[1, i].imshow(real_next_frame[i, 0].cpu().detach().numpy(), cmap='gray')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "        axes[2, i].imshow(fake_next_frame[i, 0].cpu().detach().numpy(), cmap='gray')  \n",
        "        axes[2, i].axis('off')\n",
        "\n",
        "    axes[0, 0].set_ylabel(\"Input (t-1)\")\n",
        "    axes[1, 0].set_ylabel(\"Real (t)\")\n",
        "    axes[2, 0].set_ylabel(\"Fake (t)\")\n",
        "\n",
        "    plt.savefig(f\"{save_path}/epoch_{epoch}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Inside training loop, after generator step\n",
        "if (epoch + 1) % 1 == 0:  # Save every epoch\n",
        "    visualize_samples(epoch, input_frames, real_next_frame, fake_next_frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "b2csUKWDIPrw",
        "outputId": "c36dafd4-0f4b-45cf-e366-6696b0334cca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_30352\\3628018701.py:32: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  images.append(imageio.imread(buf))\n"
          ]
        },
        {
          "data": {
            "image/gif": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import imageio\n",
        "import torch\n",
        "import numpy as np\n",
        "import io\n",
        "from IPython.display import display, Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_gif(input_frames, fake_frames, real_frames, save_path=\"generated_gif.gif\"):\n",
        "    images = []\n",
        "\n",
        "    for t in range(fake_frames.shape[1]):  # Iterate over timesteps\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "        axes[0].imshow(input_frames[0, -1].cpu().detach().numpy(), cmap='gray')  \n",
        "        axes[0].set_title(\"Input (t-1)\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(real_frames[0, t].cpu().detach().numpy(), cmap='gray')  \n",
        "        axes[1].set_title(\"Ground Truth (t)\")\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        axes[2].imshow(fake_frames[0, t].cpu().detach().numpy(), cmap='gray') \n",
        "        axes[2].set_title(\"Generated (t)\")\n",
        "        axes[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save to a buffer\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png')\n",
        "        buf.seek(0)\n",
        "        images.append(imageio.imread(buf))\n",
        "        plt.close()\n",
        "\n",
        "    # Save GIF\n",
        "    imageio.mimsave(save_path, images, duration=200)\n",
        "\n",
        "    # Display GIF in Jupyter Notebook\n",
        "    display(Image(filename=save_path))\n",
        "\n",
        "# After training:\n",
        "create_gif(input_frames, fake_next_frame, real_next_frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7933dc92ff484dcfbc74901348c053ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(Image(value=b'GIF89a\\xc0\\x00@\\x00\\x87\\x00\\x00\\x00\\x00\\x00\\x03\\x03\\x03\\x04\\x04\\x04\\x07\\x07\\x07\\x…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import io\n",
        "from IPython.display import display\n",
        "from ipywidgets import Image as WImage, HBox\n",
        "\n",
        "# Replace variable names accordingly\n",
        "input_np = input_frames.cpu().numpy().squeeze(1)\n",
        "target_np = real_next_frame.cpu().numpy().squeeze(1)\n",
        "generated_np = fake_next_frame.cpu().detach().numpy().squeeze(1)\n",
        "\n",
        "# Normalize\n",
        "def normalize(img):\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    return (img * 255).astype(np.uint8)\n",
        "\n",
        "# Create frames\n",
        "frames = []\n",
        "for i in range(len(input_np)):\n",
        "    inp = normalize(input_np[i])\n",
        "    tgt = normalize(target_np[i])\n",
        "    gen = normalize(generated_np[i])\n",
        "\n",
        "    frame = np.hstack([inp, tgt, gen])\n",
        "    frames.append(frame)\n",
        "\n",
        "# Save and display as GIF\n",
        "with io.BytesIO() as gif_buffer:\n",
        "    imageio.mimsave(gif_buffer, frames, format='GIF', duration=200)\n",
        "    output_gif = gif_buffer.getvalue()\n",
        "\n",
        "    # Save to disk\n",
        "    with open(\"pix2pix_prediction.gif\", \"wb\") as f:\n",
        "        f.write(output_gif)\n",
        "\n",
        "display(HBox([WImage(value=output_gif)]))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
